{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "\n",
    "df = pd.DataFrame(columns = ['Start', 'Number of Links','Searches','Jump/Loop Link','Efficiency','Time','Time/Search'])\n",
    "df.head()\n",
    "\n",
    "\n",
    "def findLink(paragraph):\n",
    "    #print(paragraph)\n",
    "    if 'href=\"/wiki' in paragraph:\n",
    "        #print(paragraph)\n",
    "        #print(\"theres a link\")\n",
    "        while paragraph.find(\"(\") < paragraph.find('href=\"/wiki/'):\n",
    "            #print(paragraph.find(\"(\"))\n",
    "            #print(paragraph.find('href=\"/wiki/'))\n",
    "            if paragraph.find(\"(\") == -1:\n",
    "                break\n",
    "            opening = 1\n",
    "            closing = 0\n",
    "            paragraph = paragraph[paragraph.find(\"(\")+1:]\n",
    "            while opening != closing:\n",
    "                openingIndex = paragraph.find(\"(\")\n",
    "                if openingIndex == -1:\n",
    "                    openingIndex = 100000000\n",
    "                if openingIndex < paragraph.find(\")\"):\n",
    "                    opening += 1\n",
    "                    paragraph = paragraph[paragraph.find(\"(\")+1:]\n",
    "                else:\n",
    "                    closing += 1\n",
    "                    paragraph = paragraph[paragraph.find(\")\")+1:]\n",
    "        #print(paragraph)\n",
    "        try:\n",
    "          #only using try if the only href in the paragraph is within parentheses\n",
    "          return(paragraph.split('href=\"/wiki/')[1].split('\"')[0])\n",
    "        except:\n",
    "          return(\"\")\n",
    "    else:\n",
    "        return(\"\")\n",
    "\n",
    "def strip_tables(soup):\n",
    "  count = 0\n",
    "  #print(count)\n",
    "  while count < 5:\n",
    "    #print(\"searching for table\")\n",
    "    if soup.find('<table') == -1:\n",
    "      #print(\"no more tables\")\n",
    "      return soup\n",
    "      break\n",
    "    #print(soup.find('<table'))\n",
    "    #print(\"Found table\")\n",
    "    soup = soup[:soup.find('<table')] + soup[soup.find('table>') + 6 : ]\n",
    "    count += 1\n",
    "  return soup\n",
    "\n",
    "def strip_i(soup):\n",
    "  count = 0\n",
    "  while count < 5:\n",
    "    if soup.find('<i>') == -1:\n",
    "      return soup\n",
    "    soup = soup[:soup.find('<i>')] + soup[soup.find('</i>') + 4 : ]\n",
    "    count += 1\n",
    "  return soup\n",
    "\n",
    "def strip_coordinates(soup):\n",
    "    if soup.find('span id=\"coordinates\"><a href=\"/wiki/Geographic_coordinate_system\"') == -1:\n",
    "      return soup\n",
    "    else:\n",
    "        soup = soup[:soup.find('span id=\"coordinates\"><a href=\"/wiki/Geographic_coordinate_system\"')] + soup[soup.find('span id=\"coordinates\"><a href=\"/wiki/Geographic_coordinate_system\"') + 250 : ]\n",
    "        return soup\n",
    "\n",
    "commonLinks = {\"Science\" : 6,\n",
    "              \"Country\" : 11,\n",
    "              \"Sport\" : 16,\n",
    "              \"Animal\" : 12,\n",
    "              \"Sovereign_state\": 12,\n",
    "              \"Continent\" : 16,\n",
    "              \"Language\" : 6,\n",
    "              \"Machine\" : 16}\n",
    "      \n",
    "for x in range(10):\n",
    "  startTime = time.time()\n",
    "  print(\"-----------------------------------\")\n",
    "  print(\"---------------  \" + str(x+1) + \"  ---------------\")\n",
    "  print(\"-----------------------------------\")\n",
    "  link = 'Special:Random'\n",
    "  page = requests.get('http://en.wikipedia.org/wiki/' + link)\n",
    "  #print(\"Page Loaded\")\n",
    "  soup = BeautifulSoup(page.content, 'html.parser')\n",
    "  numberOfLinks = 0\n",
    "  searches = 0\n",
    "  titles = []\n",
    "  jumpLink = \"N/A\"\n",
    "  loopTrigger = \"N/A\"\n",
    "  while link != 'Philosophy':\n",
    "      if link in commonLinks:\n",
    "        numberOfLinks += commonLinks[str(link)]\n",
    "        jumpLink = str(link)\n",
    "        break\n",
    "      #print(\"link:\", link)\n",
    "      page = requests.get('http://en.wikipedia.org/wiki/' + link)\n",
    "      #print(\"Page Loaded\")\n",
    "      soup = BeautifulSoup(page.content, 'html.parser')\n",
    "      title = soup.find('h1',attrs={'class':'firstHeading'}).get_text()\n",
    "      if title in titles:\n",
    "        print(\"Loop Encountered:\", str(link))\n",
    "        numberOfLinks = \"N/A : Loop\"\n",
    "        loopTrigger = str(link)\n",
    "        break\n",
    "      titles.append(title)\n",
    "      print(title, \"[\"+str(numberOfLinks)+\"]\")\n",
    "      ### strips the first 4 tables from the soup \n",
    "      soup = str(soup)\n",
    "      soup = strip_tables(soup)  \n",
    "      soup = strip_i(soup)\n",
    "      soup = strip_coordinates(soup)\n",
    "      #print ('stripped tables')\n",
    "\n",
    "      regex = r\"<p.+\"\n",
    "      list_of_paragraphs = re.findall(regex,str(soup))\n",
    "      #print(list_of_paragraphs)\n",
    "      \n",
    "      \n",
    "      ### Extend the text of the unordered lists if the link turns out to be blank      \n",
    "      regex = r\"<li>.+<\\/li>\"\n",
    "      list_of_paragraphs.extend(re.findall(regex,str(soup)))\n",
    "\n",
    "      link = \"\"\n",
    "      #print(list_of_paragraphs)\n",
    "      for paragraph in list_of_paragraphs:\n",
    "          link = findLink(paragraph)\n",
    "          #print(link)\n",
    "          if link != \"\":\n",
    "              break\n",
    "\n",
    "      #link = findLink(paragraph)\n",
    "      numberOfLinks += 1\n",
    "      searches += 1\n",
    "  print(\"-----------------------------------\")\n",
    "  endTime = time.time()\n",
    "  timeTaken = round((endTime - startTime),2)\n",
    "  timePerSearch = round((timeTaken/searches),2)\n",
    "  percentSaved = \"0%\"\n",
    "  if numberOfLinks == \"N/A : Loop\":\n",
    "    print('Philosophy cannot be reached from', titles[0])\n",
    "    df.loc[x] = [titles[0], numberOfLinks, searches, loopTrigger, percentSaved, timeTaken, timePerSearch]\n",
    "  else:\n",
    "    print('Philosophy is', numberOfLinks, 'links From', titles[0])\n",
    "    if jumpLink != \"N/A\":\n",
    "      print(\"Jumped from:\", jumpLink)\n",
    "      percentSaved = (str(100 - math.ceil((searches/numberOfLinks)*100))+ \" %\")\n",
    "      print(\"Saved\", numberOfLinks - searches, \"searches, or\", percentSaved)\n",
    "\n",
    "    # add the number of clicks to the df\n",
    "    df.loc[x] = [titles[0], numberOfLinks, searches, jumpLink, percentSaved, timeTaken, timePerSearch]\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
